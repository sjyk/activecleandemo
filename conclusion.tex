\section{Conclusion}
The growing popularity of predictive models in data analytics adds additional challenges in managing dirty data.
Progressive data cleaning in this setting is susceptible to errors due to mixing dirty and clean data, sensitivity to sample size, and the sparsity of errors.
The key insight of \sys is that an important class of predictive models, called convex loss models (e.g., linear regression and SVMs), can be simultaneously trained and cleaned.
Consequently, there are provable guarantees on the convergence and error bounds of \sys.  
\sys also includes numerous optimizations such as: using the information from the model to inform data cleaning on samples, dirty data detection to avoid sampling clean data, and batching updates.
The experimental results are promising as they suggest that these optimizations can significantly reduce data cleaning costs when errors are sparse and cleaning budgets are small.
Techniques such as Active Learning and SampleClean are not optimized for the sparse low-budget setting, and \sys achieves models of similar accuracy for significantly less records cleaned.