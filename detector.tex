\subsection{The Detector}\label{det}
% Partitioning Data With Detection}\label{det}
% \sys improves the progress of each update iteration by intelligently partitioning the data into expected dirty and clean partitions. 
% This ensures that sampling draws data that are likely to be dirty.

% \subsubsection{Goals}
The detector returns two important aspects of a record: 
(1) whether the record is dirty, and (2) if it is dirty, what is wrong with the record.
The sampler can use (1) to select a subset of dirty records to sample at each batch and 
the estimator can use (2) estimate the value of data cleaning based on other records with the same corruption.
\sys supports two types of detectors: \emph{a priori} and \emph{adaptive}.
In former assumes that we know the set of dirty records and how they are dirty \emph{a priori} to \sys,
while the latter \emph{adaptively} learns characteristics of the dirty data as part of running \sys.

\subsubsection{\protect\textit{\large A Priori} Detector}
For many types of dirtiness such as missing attribute values and constraint violations, 
it is possible to efficiently enumerate a set of corrupted records and determine how the records are corrupted.

\begin{definition}[A Priori Detection]
Let $r$ be a record in $R$. An a priori detector is a detector that returns a Boolean of whether the record is dirty and a set of columns $e_r$ that are dirty.
\[
D(r) = (\{0,1\}, e_r)
\]
From the set of columns that are dirty, find the corresponding features that are dirty $f_r$ and labels that are dirty $l_r$.
\end{definition}

\noindent Here is an example this definition using a data cleaning methodology proposed in the literature.

\vspace{0.5em}

\noindent\textbf{Constraint-based Repair: }
One model for detecting errors involves declaring constraints on the database.

\vspace{0.5em}

\emph{Detection. } Let $\Sigma$ be a set of constraints on the relation $\mathcal{R}$. 
In the detection step, the detector selects a subset of records $\mathcal{R}_{dirty} \subseteq \mathcal{R}$ that violate at least one constraint.
The set $e_r$ is the set of columns for each record which have a constraint violation. 

\begin{example}\label{detex1}
An example of a constraint on the running example dataset is that the \texttt{status} of
a contribution can be only ``allowed" or ``disallowed".
Any other value for \texttt{status} is an error.
\end{example}

\subsection{Adaptive Detection}
\emph{A priori} detection is not possible in all cases.
The detector also supports adaptive detection where detection is learned from previously cleaned data.
Note that this ``learning" is distinct from the ``learning" at the end of the pipeline.
The challenge in formulating this problem is that detector needs to describe how the data is dirty (e.g. $e_r$ in the \emph{a priori} case).
The detector achieves this by categorizing the corruption into $u$ classes.
These classes are corruption categories that do not necessarily align with features, but every record is classified with at most one category.

When using adaptive detection, the repair step has to clean the data and report to which of the $u$ classes the corrupted record belongs.
When an example $(x,y)$ is cleaned, the repair step labels it with one of the ${\text{clean}, 1,2,...,u+1}$ classes (including one for ``not dirty").
It is possible that $u$ increases each iteration as more types of dirtiness are discovered.
In many real world datasets, data errors have locality, where similar records tend to be similarly corrupted.
There are usually a small number of error classes even if a large number of records are corrupted.

One approach for adaptive detection is using a statistical classifier. 
This approach is particularly suited for a small number data error classes, each of which containing many erroneous records.
This problem can be addressed by any classifier, and we use an all-versus-one SVM in our experiments.

Another approach could be to adaptively learn predicates that define each of the error classes.
For example, if records with certain attributes are corrupted, a pattern tableau can be assigned to each class to select a set of possibly corrupted records.
This approach is better suited than a statistical approach for a large number of error classes or scarcity of errors.
However, it relies on errors being well aligned with certain attribute values.

\begin{definition}[Adaptive Case]
Select the set of records for which $\kappa$ gives a positive error classification (i.e., one of the $u$ error classes).
After each sample of data is cleaned, the classifier $\kappa$ is retrained.
So the result is:
\[D(r) = (\{1,0\},\{1,...,u+1\})\]
\end{definition}

\vspace{0.75em}

\noindent\textbf{Adaptive Detection With OpenRefine: }
\begin{example}\label{detex2}
OpenRefine is a spreadsheet-based tool that allows users to explore and transform data.
However, it is limited to cleaning data that can fit in memory on a single computer.
Since the cleaning operations are coupled with data exploration, \sys does not know what is dirty in advance (the analyst may discover new errors as she cleans).

Suppose the analyst wants to use OpenRefine to clean the running example dataset with \sys.
She takes a sample of data from the entire dataset and uses the tool to discover errors.
For example, she finds that some drugs are incorrectly classified as both drugs and devices.
She then removes the device attribute for all records that have the drug name in question.
As she fixes the records, she tags each one with a category tag of which corruption it belongs to.
\end{example}





