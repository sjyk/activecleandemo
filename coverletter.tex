{\noindent \normalsize \bf Dear SIGMOD Chair and Referees: }

\vspace{.5em}

We thank the reviewers and chair for the helpful feedback on our paper. 
We addressed all of the concerns and included references to the revised text. 
To summarize the major changes:

\begin{enumerate}
\item Sections 1 and 2 clarify the contributions of \sys and its relationship to related work.

\item In Section \ref{dmodel}, we formalize the definition of dirty data and the data cleaning model.

\item Section \ref{s:usecase} presents a running example that is referenced in each technical section (Examples \ref{archex}, \ref{upex},\ref{detex1},\ref{detex2},\ref{estex}).

\item In Section \ref{statements}, we revised the problem statement to be independent of our solution method. The section highlights two subproblems, correctness and efficiency, which are used to organize the technical sections.

\item Section \ref{arch} presents a revised system architecture that first emphasizes the essential components for correctness, and then highlights optional optimizations. 

\item We have re-organized and re-written the technical sections to improve readability (Sections \ref{model-update}-\ref{opti}).

\item We include references to all of the related work suggested by the reviewing committee \cite{whang2014incremental, papenbrock2015progressive, gruenheid2014incremental, DBLP:journals/pvldb/YakoutENOI11, yakout2013don, heise2014estimating}.
\end{enumerate}


\subsection*{Overview} 
Data cleaning is often applied before featurization and predictive modeling to provide clean training data.
Corruption of the training data can degrade model quality, and high-dimensional models can amplify small errors.
Unfortunately, data cleaning is often a manual and time consuming process, and may be impractical for very large datasets.
\sys is a framework that allows users to train accurate models without having to clean the entire dataset. 
\sys couples data cleaning with model training to leverage information from the model to identify records that maximally improve accuracy.
The paper shows that naive integration of data cleaning and model training can lead to convergence problems, and we present a novel framework for training on partially clean data.
Specifically, it applies: (1) a gradient-based update derived from small batches of cleaned data, (2) weighted sampling to carefully select these batches, (3) optimizations to select records that are most likely to be dirty.

As the name implies, \sys is inspired by active learning and both seek to improve the efficiency of expensive manual or crowdsourced data cleaning.
Prior work applies active learning to most efficiently clean an entire dataset--independent of the user's desired analysis after data cleaning.
In contrast, for a large class of predictive models, \sys prioritizes data cleaning by identifying records, which if cleaned, are likely to change the model's predictions.
The key new challenge is that model training on a mixture of clean data and not-yet-cleaned dirty data, can lead to severe inaccuracy due to a well-studied phenomenon called Simpson's paradox (Section \ref{correctness}).
Consequently, we propose a new model update algorithm that provably avoids this problem, and integrate the prioritization with this algorithm.

\vspace{0.5em}

\subsection*{Meta Review Details} 

\noindent\noindent \textbf{M1. There should be a formal vocabulary introduced early on. The exact idea of ``dirty" here can be hard to follow: what is the exact error type(s) that the system is intended to clean?}

\vspace{0.5em}

We added a section that clarifies that our system supports data cleaning operations that can be represented as record-by-record mappings (Section \ref{dmodel}).
Formally, there exists a function (implemented via human or algorithm) that given a dirty record will return a unique clean record.
This definition does not include errors that simultaneously affect multiple records such as duplication or schema transformation problems.
We emphasize this limitation early in the introduction (Section 1) and background (Section 2)sections.

%Details are provided in Response \textbf{R2.1}.

\vspace{0.5em}

\noindent\textbf{M2a. Sections 5-7 are the technical core of the paper, and appear formal at the expense of aiding understanding.}

We have revised the technical sections of the paper to improve readability by moving derivations to the appendix and including three new examples.

\vspace{0.5em}

\noindent \textbf{M2b. They appear to implement something that resembles active learning or bootstrapping, except inside the gradient descent loop. The motivation of some of this is not clear; is it necessary to integrate with the gradient descent?} 

Yes, the integration with gradient descent is necessary as it allows for provable guarantees about the model's convergence.
We have revised the paper to intuitively motivate this problem in Section \ref{correctness}, formally describe the problem in Section \ref{updp}, and simplified the presentation of the gradient-based update solution in Section \ref{geod}.

\vspace{0.5em}

\noindent\textbf{M2c. This is not how most active learning methods are implemented. Is it possible to implement these approaches in a way that is orthogonal to the SGD algorithm? The current writeup entangles some of these design choices.} 

We have revised the paper to decouple two subproblems: (1) the correctness problem of how to update a model after cleaning, and (2) the efficiency problem of how to prioritize cleaning using the model. 
Problem (1) is addressed with SGD.
The solution to problem (2) is independent of the update problem, although we highlight its optimality properties with respect to SGD.
We clarify that any sampling algorithm that ensures that all dirty records have a non-zero sampling probability can be applied.
We also have re-organized the paper to isolate optimizations from the essential components of \sys.
In the revision, Section \ref{opti} describes optimizations that improve the convergence rate of the system.
%We describe a number of cases when these optimizations are possible.

\vspace{0.5em}

\noindent\textbf{M3. In general, the distinction between an ``architecture" and an ``algorithm that fits into the architecture" is quite unclear. The problem with SGD/Active Learning above is one example.}

We have significantly revised the architecture section of the paper.
We first separate the formal problem statement (Section \ref{statements}) and system architecture (Section \ref{arch}).
The architecture section now describes the essential data flows of the system and is orthogonal to the solutions of the problems described in Section \ref{statements}.
We also differentiate the essential components of the architecture and the optional instance-specific optimizations.
The new architecture would apply even if the model update problem was addressed with a different algorithm (i.e., not SGD).
%We also clearly identify the user inputs in Section \ref{uinp}.

\vspace{0.5em}

\noindent\textbf{M4. The paper, and especially the technical sections, would benefit enormously from a detailed running example showing how the algorithm works}

We have added examples to each of the technical sections based on our running example of an analyst using an SVM for fraud detection. 
Section 4 (Architecture) describes an intuitive end-to-end application (Example \ref{archex}).
Section 5 (Update Problem) describes how updates are propagated and calculated (Example \ref{upex}).
%Section 7.1 (Detection) contains two examples for how the two different types of detectors can be used (Examples \ref{detex1} and \ref{detex2}).
Section 7.2 describes how to apply the optimizations to this example.

\vspace{0.5em}

\noindent\textbf{M5. Some connections to related work that combines machine learning and data cleaning should be made. See the other reviewers' comments.}

We have added Section \ref{alrw} to connect \sys to related work that applies machine learning to data cleaning.
This was a source of significant confusion in the initial submission, and we have clarified the key differences.
We have also revised our related work section to highlight the suggested references to progressive data cleaning and entity resolution~(Section \ref{rw}).
%Details are provided in Response \textbf{R1.4} and Response \textbf{R2.2}.

\subsection*{Review 1 Details} 

\noindent\textbf{R1.1: At first, the problem seems a bit too specialized. The abstract is too loaded with technical terms and a turn-off. This is then mitigated in the introduction. \\
As mentioned above, the abstract is (to me) overly technical and did not make me curious. I did not know off the bat what a convex loss model is, what importance sampling is, etc.}

\noindent We revised the abstract to better motivate our problem and solutions:

\emph{Data cleaning is often applied before predictive modeling, such as regression and classification, to provide clean training data.
The high dimensionality of predictive models can amplify small amounts of data error leading to error-prone predictions.
Unfortunately, data cleaning can be a manual and time consuming process, and may be impractical for very large datasets.
This paper explores techniques to train accurate models without having to clean the entire dataset.
We propose \sys, a progressive cleaning approach where data is simultaneously cleaned as the model is trained.
As more data is cleaned, the accuracy of the model gradually converges.
The challenge is that models trained on partially cleaned data can be arbitrarily incorrect; requiring a new algorithm for incrementally updating results given newly cleaned data.
\sys supports a popular class of models called convex loss models (e.g., linear regression and SVMs) and record-by-record data cleaning operations.
By coupling data cleaning and model training, \sys can leverage the structure of a user's model to prioritize cleaning those records likely to affect the results.
Evaluation on four real-world datasets suggests that for a fixed cleaning budget, \sys returns more accurate models than uniform sampling and Active Learning when corruption is systematic and sparse. }

\vspace{0.5em}

\noindent\textbf{R1.2: Poor embrace of the duplicate detection problem (see details below). Your model of the cleaner seems to preclude any duplicate detection, which certainly cannot happen on individual records. Also you extension for a set of record does not fit the problem of duplicate detection. This is in contrast, for instance, to your ER example in the second column of that page. Appendix A.1 is misleading here, as you mention with Example 7 ``in entity resolution problems..." but do not actually address that problem in the example. Fixing some common inconsistency is not entity resolution.}

We apologize for the confusing terminology and have revised our paper to clarify that we do not address record-level deduplication and entity resolution.

\vspace{0.5em}

\noindent\textbf{R1.3: Cheated by using a narrower font than required. Will have trouble with camera ready copy if publisher insists on proper font.\\
- I would not use ``overview" as a verb...
- 3.2: the detector select -> the detector selects
- 4.3: Wrong quotation marks around ``learning".
- QED symbols on page 8 are ugly when placed directly after formula. 
- References need a clean up. Just as an example: Venue is missing for [24], year is mentioned 3 times for [8], [11], etc. Page numbers appear sporadically.}

\noindent We have addressed all of the formatting and copy editing issues.

\vspace{0.5em}

\noindent\textbf{R1.4:There is some related work specifically addressing progressive/incremental entity resolution. You might want to point your readers to this.
\\E.g.
\\- Incremental entity resolution on rules and data, Whang et al. VLDB Journal 2014
\\- Progressive duplicate detection, Papenbrock et al., TKDE 2015
\\- Incremental record linkage, Gruenheid et al., PVLDB 2014
\\- Another work that is related is ``Estimating the Number and Sizes of Fuzzy-Duplicate Clusters" by Heise et al. CIKM 2014, which also incrementally cleans samples of data to predict in this case the number of record matches.}

Thank you for highlighting these references, and we have included them in our related work:

\emph{When data cleaning is expensive, it is desirable to apply it \textbf{progressively}, where analysts can inspect early results with only $k \ll N$ records cleaned.
Progressive data cleaning is a well studied problem especially in the context of entity resolution \cite{altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.
Prior work has focused on the problem of designing data structures and algorithms to apply data cleaning progressively. which is challenging because many data cleaning algorithms require information from the entire relation.
Over the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning~\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}.
\sys studies the problem of prioritizing progressive cleaning by leveraging information about a user's subsequent use for the data.
Certain records, if cleaned, may be more likely to affect the downstream analysis.\\
SampleClean~\cite{wang1999sample} applies data cleaning to a sample of data, and estimates the results of aggregate queries.
Sampling has also been applied to estimate the number of duplicates in a relation \cite{heise2014estimating}. 
Similarly, Bergman et al. explore the problem of query-oriented data cleaning \cite{DBLP:conf/sigmod/BergmanMNT15}, where given a query, they clean data relevant to that query. 
Existing work does not explore cleaning driven by the downstream machine learning ``queries" studied in this work.}

\vspace{0.5em}

\noindent\textbf{- Page 1, last paragraph in column 1 reads as if reference to [3] is a reaction to the work referenced in the previous sentence, i.e., the term ``remains" is misleading.
- I did not quite understand the short paragraph on crowd-sourcing. Why is this even relevant?
 I believe it would suffice to simply state that cleansing is expensive...}

We appreciate the thorough feedback and have tightened up the writing in the introduction. In particular, we have consolidated the motivation to a single paragraph describing the expense of data cleaning. We include a single sentence referencing related work on crowdsourcing/human-guided data cleaning.


\subsection*{Review 2 Details}

\noindent\textbf{R2.1: The definition of ``clean data" is imprecise and not clear. It appears that ``cleaning" in this system refers to entity resolution, cleaning w.r.t. dependencies, and possibly other actions as needed by the application. This makes it difficult to gauge overall accuracy when there are different interpretations of cleanliness. It is not clear how entity resolution and cleaning w.r.t. dependencies can be done holistically.}

We added Section \ref{dmodel} to the paper which clarifies the supported data cleaning operations:

\emph{\sys supports data cleaning operations that can be represented as record-by-record transformations.
Formally, there exists a function (implemented via human or algorithm) that given a dirty record will return a unique clean record.
This definition does not cover errors that simultaneously affect multiple records such as record duplication or schema transformation problems.
We represent this operation as $C(\cdot)$ which can be applied to a record $r$ to recover the clean record $r' = C(r)$.
Therefore, for every $r \in R$ there exists a unique $r' \in R^*$, where $R^*$ is the hypothetical fully cleaned relation.
We assume that there is a featurizer $F(\cdot)$ that maps a record to a feature vector $x$ and a label vector $y$.
So each record corresponds to one training example for the downstream model.}

\vspace{0.5em}

Our appendix (Section \ref{set-of-r}) also describes an extension to this model where sets of records can be cleaned at once (e.g., a find-and-replace operation).

\vspace{0.5em}

\noindent\textbf{R2.2: The paper describes a problem setting focused on modelling the iterative cleaning process rather than actual data management problems. The paper may be better suited at an ML venue.}

Over the last 5 years a number of new results have expanded the scope of progressive and interactive data cleaning~\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don, altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.
However,  it turns out that the straight-forward integration of existing progressive data cleaning methods with model training can lead to error-prone and misleading results due to the well studied Simpson's paradox (Section \ref{correctness}).
Recognizing that data analytics is increasingly moving towards predictive modeling, \sys presents an initial exploration of this problem.  

\vspace{0.5em}

\noindent\textbf{R2.3: Missing references to related work on interactive data cleaning. For the comparative evaluation, 2/3 techniques are ML based techniques, not interactive data cleaning systems. See D2.\\
D2: Data cleaning systems have also considered interactive engagement with the user and the application of ML techniques. 
i) Mohamed Yakout, Laure Berti-Equille, Ahmed K. Elmagarmid. Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes. SIGMOD Conference 2013: 553-564
ii) Mohamed Yakout, Ahmed K. Elmagarmid, Jennifer Neville, Mourad Ouzzani, Ihab F. Ilyas.
Guided data repair. PVLDB 4(5): 279-289 (2011).
}

Prior work in data cleaning applies active learning to most efficiently clean an entire dataset--independent of the user's desired analysis after data cleaning.
On the other hand, \sys explores the problem of data cleaning to provide clean training data for a predictive modeling problem.
It identifies records to clean that maximally change the user's modeling results.
We added Section \ref{alrw} to clarify this distinction:

\emph{Next, we contrast \sys and existing data cleaning approaches.
Machine learning, specifically active learning, has been applied in prior work to improve the efficiency of data cleaning~\cite{yakout2013don,DBLP:journals/pvldb/YakoutENOI11,gokhale2014corleone}.
Human input, either for cleaning or validation of automated cleaning, is often expensive and impractical for large datasets.
A model can learn rules from a small set of examples cleaned (or validated) by a human, and active learning is a technique to carefully select the set of examples to learn the most accurate model.
This model can be used to extrapolate repairs to not-yet-cleaned data, and the goal of these approaches is to provide the cleanest possible dataset--independent of the subsequent analytics or query processing.\\
As the name implies, \sys is inspired from active learning as both seek to improve the efficiency of expensive data cleaning.
In contrast, \sys addresses a very different problem, namely, how information about a user's subsequent data analysis can inform which data to clean.
If the cleaned data will ultimately be used as training data in a predictive model, \sys presents an algorithm to prioritize those data that are most likely to change the result.
The key new challenge is correctness.
Models trained on partially clean data can have severe inaccuracies.
Thus, existing approaches, which are designed for homogeneous data, cannot be applied.
One of the primary contributions of this work is an incremental model update algorithm with correctness guarantees for mixtures of data.
An active learning-like algorithm can be applied in conjunction with the proposed model update algorithm while preserving correctness.
However, the new problem setting also has several additional opportunities for optimizations, which empirically can significantly improve the convergence rate of typical active learning criteria (Section \ref{eval}).}

\vspace{0.5em}

We also included additional details in the related work section (Section \ref{rw}):

\emph{There are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning~\cite{DBLP:journals/pvldb/YakoutENOI11,yakout2013don,gokhale2014corleone}.
For example, Yakout et al. train a model that evaluates the likelihood of a proposed replacement value \cite{yakout2013don}.
Another application of machine learning is value imputation, where a missing value is predicted based on those records without missing values.
Machine learning is also increasingly applied to make automated repairs more reliable with human validation \cite{DBLP:journals/pvldb/YakoutENOI11}.
Human input is often expensive and impractical to apply to entire large datasets.
Machine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data \cite{gokhale2014corleone, DBLP:journals/pvldb/YakoutENOI11}.
This approach can be coupled with active learning \cite{DBLP:journals/pvldb/MozafariSFJM14} to learn an accurate model with the fewest possible number of examples.
While, in spirit, \sys is similar to these approaches, it addresses a very different problem of data cleaning before user-specified modeling.
The key new challenge in this problem is ensuring the correctness of the user's model after partial data cleaning.}

\textbf{R2.4: Sampling is an important part of the framework and influences the accuracy of the cleaning. Yet, there is little discussion on sampling rate, or how a sample is chosen.}

We have added a new section (Section 6), which is dedicated to describing the basic sampling algorithm.
Section 7 has been revised to describe optimizations to this algorithm.

\vspace{0.5em}

\textbf{R2.5: An end-to-end running example in Section 5 is needed to highlight the intuition of the cleaning process.}

We included a running example of fraud detection on dirty data. Each of the technical sections ends with a reference to this running example (see response \textbf{M4}).


\vspace{0.5em}


\subsection*{Review 3 Details}
\noindent\textbf{R3.1: The authors do not distinguish between the system architecture and the individual issues that they are presenting.}

Response \textbf{M3} describes several revisions to the architecture including: separating problem formalization and architecture, discussing the data flow rather than the algorithms, and differentiating the essential components for correctness from optimizations.

\vspace{0.5em}

\noindent\textbf{R3.2: The paper uses lots of definitions, and a multitude of that do not necessarily contribute to readability.
Without being an expert in the field, I found it extremely difficult to follow the paper as it touches upon multiple problems at the same time: data cleaning, model training, convex analytics, etc., uses definitions, notation and lots of examples that did not allow me to have a global understanding of the work.\\
I would prefer to have a more focused paper on one of these aspects that has concrete goals and then, having an overview of the architecture of the system as a small section. I believe that the architecture should not be the focus and the skeleton of this paper. Instead, I believe that the authors could focus on the individual problems.}

We have discussed a number of specific textual revisions in response \textbf{M2} and \textbf{M3}. Here are a list of other revisions to improve the readability:

\begin{enumerate}
\item We have significantly revised the paper to make it more accessible and readable. Where possible, we have simplified, or even removed, notation and definitions. We also included Section \ref{notation} to summarize all of the important notation before the technical sections.
\item We have expanded the background section to provide a more detailed setup and context to the problem.
\item We revised the technical sections to first present a minimum viable solution that addresses the two subproblems (Section \ref{model-update} and Section  \ref{dist-samp}).
\item The next section (Section \ref{opti}) describes optional optimizations that can be applied in a number of practical cases.
\item Detailed derivations are now in the appendix, and the additional space has been used for three new examples in the technical sections (Sections \ref{model-update}-\ref{opti}).
\end{enumerate}
