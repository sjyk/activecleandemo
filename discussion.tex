\section{Discussion and Future Work}
The experimental results suggest the following conclusions about \sys: (1) when the data corruption rate is relatively small (e.g., 5\%), \sys cleans fewer records than Active Learning or SampleClean to achieve the same model accuracy, (2) all of the optimizations in \sys (importance sampling, detection, and estimation) lead to significantly more accurate models at small sample sizes, (3) only when corruption rates are very severe (e.g. 50\%) , SampleClean outperforms \sys, and (4) two real-world scenarios demonstrate similar accuracy improvements where \sys returns significantly more accurate models than SampleClean or Active Learning for the same number of records cleaned.

There are also a few additional points for discussion.
\sys provides guarantees for training error on models trained with progressive data cleaning, however, there are no such guarantees on test error. 
This work focuses on the problem where an analyst has a large amount of dirty data and would like explore data cleaning and predictive models on this dataset.
By providing the analyst more accurate model estimates, the value of different data cleaning techniques can be judged without having to clean the entire dataset.
However, the exploratory analysis problem is distinct from the model deployment problem (i.e., serving predictions to users from the model), which we hope to explore in more detail in future work.
It implicitly assumes that when the model is deployed, it will be applied in a setting where the test data is also clean.
Training on clean data, and testing on dirty data, defeats the purpose of data cleaning and can lead to unreliable predictions.

As the experiments clearly show, \sys is not strictly \emph{better} than Active Learning or SampleClean.
\sys is optimized for a specific design point of sparse errors and small sample sizes, and the empirical results suggest it returns more accurate models in this setting.
As sample sizes and error rates increase, the benefits of \sys are reduced.
Another consideration for future work is automatically selecting alternative techniques when \sys is expected to perform poorly.

Beyond these limitations, there are several exciting new avenues for future work.
The data cleaning models explored in this work can be extended to handle non-uniform costs, where different errors have a different cleaning cost.
Next, the empirical success of Deep Learning has led to increasing industry and research adoption of non-convex losses in many tasks that were traditionally served by convex models.
In future work, we hope to explore how we can integrate with such frameworks.

