\section{Adaptive Error Detection}\label{imperfect} 
In this section, we explore how we can handle the case where the error detection is learned as we clean data.

\subsection{Challenges}
In this section, we explore the partitioning model, where as we clean more data, we iteratively prune data we expect to be clean from $R_{dirty}$.
This is done with a classifier that is updated with new training data based on the previous iterations results.
The main challenge is that the sampling weights calculated in the previous section are dependent on the error detection step returning a set of corrupted features.
When we relax this assumption, there are new challenges in error estimation.
Next, an important aspect of our gradient update is partitioning the dirty and clean data.
We aggregate an average gradient from both subpopulations when making our update.
However, in some cases, characterizing this partioning can be difficult and it may be impossible to ensure this condition unless $R_{dirty} = R$ causing a loss in efficiency if errors are sparse. 

\subsection{Error Classes}
When we relax the restrictions on the error detection step, we no long have a set of corrupted features $e_r$.
This breaks the decoupling argument that we made in the previous section.
However, our high-level goal in the previous section, was to estimate the gradient for groups of similarly corrupted records.
We try to formulate an analogous methodology that generalizes what we did in the previous section to error detection steps that are learned over time.
Instead of assuming that we know which features are corrupted, let us say that we know that there are $u$ classes of errors.
As the analyst cleans data, she tags dirty data with one of the $u$ classes.
Then, the error detection problem reduces to a multiclass classification problem.
Once classified, we can apply an average change conditioned on the error class.

With this intuition in mind, we have to revise our error repair step:
\vspace{0.5em}

\noindent\textbf{Error Repair: } When an example $(x,y)$ is cleaned, the repair step also has to provide a label of to which of the ${\text{clean}, 1,2,...,u}$ classes it belongs. It is possible that $u$ increases each iteration as more errors are discovered. 

\vspace{0.5em}

Suppose, we have a multi-class classifier $\kappa$ (e.g. SVM) that classifies every record $r$ into $u+1$ classes (the $u$ error types or not dirty).
Thus, we revise the partitioning in the following way:

\vspace{0.5em}

\noindent\textbf{Error Detection: } To select $R_{dirty}$, we select the set of records for which $\kappa$ give a positive error classification (i.e., one of the $u$ error classes).
Many types of classifiers allow users to tradeoff precision and recall.
In other words, we can also select any record within some level of confidence of the classification margin.
For an SVM, we may only classify a point as clean if it is sufficiently far from the margin.
Or for Logistic Regression, we may do so if its class likelihood is over 80\%.

\subsection{Error Estimate}
Our model update framework still holds in this setting, however, our error estimation framework requires some modification.
In our derivation, we showed that our error estimate was a linearization of the conditional expectation of the gradient.
Instead of conditioning on the features that are corrupted, we condition the error classes.
So for each error class, we compute a $\Delta_{xu}$ and $\Delta_{yu}$.
These are the average change in the features given that class and the average change in labels given that class respectively.
\[
p_{r,u}\propto\|\nabla\phi(x,y,\theta^{(t)}) + M_x \cdot \Delta_{ux} +  M_y \cdot \Delta_{uy}\|
\] 

